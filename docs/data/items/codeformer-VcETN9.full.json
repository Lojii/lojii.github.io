{
  "id": "codeformer-VcETN9",
  "type": "repo",
  "name": "CodeFormer",
  "nameEn": "CodeFormer",
  "url": "https://github.com/sczhou/CodeFormer",
  "summary": "ËøàÂêëÂü∫‰∫éÁ†ÅÊú¨Êü•ÊâæTransformerÁöÑÈ≤ÅÊ£íÁõ≤‰∫∫ËÑ∏Â§çÂéü",
  "description": "",
  "notes": "",
  "images": [
    "/assets/images/codeformer-VcETN9/3.jpg",
    "/assets/images/codeformer-VcETN9/2.jpg",
    "/assets/images/codeformer-VcETN9/4.jpg"
  ],
  "thumbnail": "/assets/images/codeformer-VcETN9/2.jpg",
  "category": "ai",
  "tags": [
    "ÁÖßÁâáÊÅ¢Â§ç"
  ],
  "github": {
    "stars": 17765,
    "forks": 3693,
    "language": "Python",
    "license": "NOASSERTION",
    "lastUpdate": "2026-01-22",
    "topics": [
      "codebook",
      "codeformer",
      "face-enhancement",
      "face-restoration",
      "pytorch",
      "restoration",
      "super-resolution",
      "vqgan"
    ],
    "createdAt": "2022-06-21"
  },
  "archived": false,
  "createdAt": "2026-01-22",
  "updatedAt": "2026-01-22",
  "originalContent": "<div id=\"readme\" class=\"md\" data-path=\"README.md\"><article class=\"markdown-body entry-content container-lg\" itemprop=\"text\"><p align=\"center\" dir=\"auto\">\n  <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/CodeFormer_logo.png\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/CodeFormer_logo.png\" height=\"110\" style=\"max-width: 100%; height: auto; max-height: 110px;\"></a>\n</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Towards Robust Blind Face Restoration with Codebook Lookup Transformer (NeurIPS 2022)</h2><a id=\"user-content-towards-robust-blind-face-restoration-with-codebook-lookup-transformer-neurips-2022\" class=\"anchor\" aria-label=\"Permalink: Towards Robust Blind Face Restoration with Codebook Lookup Transformer (NeurIPS 2022)\" href=\"#towards-robust-blind-face-restoration-with-codebook-lookup-transformer-neurips-2022\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\"><a href=\"https://arxiv.org/abs/2206.11253\" rel=\"nofollow\">Paper</a> | <a href=\"https://shangchenzhou.com/projects/CodeFormer/\" rel=\"nofollow\">Project Page</a> | <a href=\"https://youtu.be/d3VDpkXlueI\" rel=\"nofollow\">Video</a></p>\n<p dir=\"auto\"><a href=\"https://colab.research.google.com/drive/1m52PNveE4PBhYrecj34cnpEeiHcC5LTb?usp=sharing\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/eff96fda6b2e0fff8cdf2978f89d61aa434bb98c00453ae23dd0aab8d1451633/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667\" alt=\"google colab logo\" data-canonical-src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"max-width: 100%;\"></a> <a href=\"https://huggingface.co/spaces/sczhou/CodeFormer\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b7c73a15a959c8eee2e61164cbc909c76c1aae17f334ac1b4c18b00ef8ea2745/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f44656d6f2d25463025394625413425393725323048756767696e67253230466163652d626c7565\" alt=\"Hugging Face\" data-canonical-src=\"https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue\" style=\"max-width: 100%;\"></a> <a href=\"https://replicate.com/sczhou/codeformer\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ae2c10806a46b9d89acbbaac90dce988d8a2cce8bf982cc7169f73ac091ed152/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f44656d6f2d2546302539462539412538302532305265706c69636174652d626c7565\" alt=\"Replicate\" data-canonical-src=\"https://img.shields.io/badge/Demo-%F0%9F%9A%80%20Replicate-blue\" style=\"max-width: 100%;\"></a> <a href=\"https://openxlab.org.cn/apps/detail/ShangchenZhou/CodeFormer\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9073d1c0da1c5161ebbd5d32df06f1adcae20760827cb099f6cd41fb5b662f62/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f44656d6f2d2546302539462539302542432532304f70656e584c61622d626c7565\" alt=\"OpenXLab\" data-canonical-src=\"https://img.shields.io/badge/Demo-%F0%9F%90%BC%20OpenXLab-blue\" style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6dcb592f4f7311247c0283014d701579433026fa3ba858eb872c46d14af86ca5/68747470733a2f2f6170692e696e66696e6974657363726970742e636f6d2f62616467656e2f636f756e743f6e616d653d73637a686f752f436f6465466f726d6572266c746578743d56697369746f7273\"><img src=\"https://camo.githubusercontent.com/6dcb592f4f7311247c0283014d701579433026fa3ba858eb872c46d14af86ca5/68747470733a2f2f6170692e696e66696e6974657363726970742e636f6d2f62616467656e2f636f756e743f6e616d653d73637a686f752f436f6465466f726d6572266c746578743d56697369746f7273\" alt=\"Visitors\" data-canonical-src=\"https://api.infinitescript.com/badgen/count?name=sczhou/CodeFormer&amp;ltext=Visitors\" style=\"max-width: 100%;\"></a></p>\n<p dir=\"auto\"><a href=\"https://shangchenzhou.com/\" rel=\"nofollow\">Shangchen Zhou</a>, <a href=\"https://ckkelvinchan.github.io/\" rel=\"nofollow\">Kelvin C.K. Chan</a>, <a href=\"https://li-chongyi.github.io/\" rel=\"nofollow\">Chongyi Li</a>, <a href=\"https://www.mmlab-ntu.com/person/ccloy/\" rel=\"nofollow\">Chen Change Loy</a></p>\n<p dir=\"auto\">S-Lab, Nanyang Technological University</p>\n<p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/network.jpg\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/network.jpg\" width=\"800px\" style=\"max-width: 100%;\"></a></p>\n<p dir=\"auto\">‚≠ê If CodeFormer is helpful to your images or projects, please help star this repo. Thanks! ü§ó</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Update</h3><a id=\"user-content-update\" class=\"anchor\" aria-label=\"Permalink: Update\" href=\"#update\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<ul dir=\"auto\">\n<li><strong>2023.07.20</strong>: Integrated to üêº <a href=\"https://openxlab.org.cn/apps\" rel=\"nofollow\">OpenXLab</a>. Try out online demo! <a href=\"https://openxlab.org.cn/apps/detail/ShangchenZhou/CodeFormer\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9073d1c0da1c5161ebbd5d32df06f1adcae20760827cb099f6cd41fb5b662f62/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f44656d6f2d2546302539462539302542432532304f70656e584c61622d626c7565\" alt=\"OpenXLab\" data-canonical-src=\"https://img.shields.io/badge/Demo-%F0%9F%90%BC%20OpenXLab-blue\" style=\"max-width: 100%;\"></a></li>\n<li><strong>2023.04.19</strong>: üê≥ Training codes and config files are public available now.</li>\n<li><strong>2023.04.09</strong>: Add features of inpainting and colorization for cropped and aligned face images.</li>\n<li><strong>2023.02.10</strong>: Include <code>dlib</code> as a new face detector option, it produces more accurate face identity.</li>\n<li><strong>2022.10.05</strong>: Support video input <code>--input_path [YOUR_VIDEO.mp4]</code>. Try it to enhance your videos! üé¨</li>\n<li><strong>2022.09.14</strong>: Integrated to ü§ó <a href=\"https://huggingface.co/spaces\" rel=\"nofollow\">Hugging Face</a>. Try out online demo! <a href=\"https://huggingface.co/spaces/sczhou/CodeFormer\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b7c73a15a959c8eee2e61164cbc909c76c1aae17f334ac1b4c18b00ef8ea2745/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f44656d6f2d25463025394625413425393725323048756767696e67253230466163652d626c7565\" alt=\"Hugging Face\" data-canonical-src=\"https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue\" style=\"max-width: 100%;\"></a></li>\n<li><strong>2022.09.09</strong>: Integrated to üöÄ <a href=\"https://replicate.com/explore\" rel=\"nofollow\">Replicate</a>. Try out online demo! <a href=\"https://replicate.com/sczhou/codeformer\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ae2c10806a46b9d89acbbaac90dce988d8a2cce8bf982cc7169f73ac091ed152/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f44656d6f2d2546302539462539412538302532305265706c69636174652d626c7565\" alt=\"Replicate\" data-canonical-src=\"https://img.shields.io/badge/Demo-%F0%9F%9A%80%20Replicate-blue\" style=\"max-width: 100%;\"></a></li>\n<li><a href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/docs/history_changelog.md\"><strong>More</strong></a></li>\n</ul>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">TODO</h3><a id=\"user-content-todo\" class=\"anchor\" aria-label=\"Permalink: TODO\" href=\"#todo\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" aria-label=\"Completed task\" checked=\"\"> Add training code and config files</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" aria-label=\"Completed task\" checked=\"\"> Add checkpoint and script for face inpainting</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" aria-label=\"Completed task\" checked=\"\"> Add checkpoint and script for face colorization</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" aria-label=\"Completed task\" checked=\"\"> <del>Add background image enhancement</del></li>\n</ul>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">üêº Try Enhancing Old Photos / Fixing AI-arts</h4><a id=\"user-content-panda_face-try-enhancing-old-photos--fixing-ai-arts\" class=\"anchor\" aria-label=\"Permalink: :panda_face: Try Enhancing Old Photos / Fixing AI-arts\" href=\"#panda_face-try-enhancing-old-photos--fixing-ai-arts\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\"><a href=\"https://imgsli.com/MTI3NTE2\" rel=\"nofollow\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/imgsli_1.jpg\" height=\"226px\" style=\"max-width: 100%; height: auto; max-height: 226px;\"></a> <a href=\"https://imgsli.com/MTI3NTE1\" rel=\"nofollow\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/imgsli_2.jpg\" height=\"226px\" style=\"max-width: 100%; height: auto; max-height: 226px;\"></a> <a href=\"https://imgsli.com/MTI3NTIw\" rel=\"nofollow\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/imgsli_3.jpg\" height=\"226px\" style=\"max-width: 100%; height: auto; max-height: 226px;\"></a></p>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Face Restoration</h4><a id=\"user-content-face-restoration\" class=\"anchor\" aria-label=\"Permalink: Face Restoration\" href=\"#face-restoration\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/restoration_result1.png\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/restoration_result1.png\" width=\"400px\" style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/restoration_result2.png\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/restoration_result2.png\" width=\"400px\" style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/restoration_result3.png\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/restoration_result3.png\" width=\"400px\" style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/restoration_result4.png\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/restoration_result4.png\" width=\"400px\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Face Color Enhancement and Restoration</h4><a id=\"user-content-face-color-enhancement-and-restoration\" class=\"anchor\" aria-label=\"Permalink: Face Color Enhancement and Restoration\" href=\"#face-color-enhancement-and-restoration\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/color_enhancement_result1.png\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/color_enhancement_result1.png\" width=\"400px\" style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/color_enhancement_result2.png\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/color_enhancement_result2.png\" width=\"400px\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Face Inpainting</h4><a id=\"user-content-face-inpainting\" class=\"anchor\" aria-label=\"Permalink: Face Inpainting\" href=\"#face-inpainting\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/inpainting_result1.png\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/inpainting_result1.png\" width=\"400px\" style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/assets/inpainting_result2.png\"><img src=\"https://raw.githubusercontent.com/sczhou/CodeFormer/HEAD/assets/inpainting_result2.png\" width=\"400px\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Dependencies and Installation</h3><a id=\"user-content-dependencies-and-installation\" class=\"anchor\" aria-label=\"Permalink: Dependencies and Installation\" href=\"#dependencies-and-installation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<ul dir=\"auto\">\n<li>Pytorch &gt;= 1.7.1</li>\n<li>CUDA &gt;= 10.1</li>\n<li>Other required packages in <code>requirements.txt</code></li>\n</ul>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"# git clone this repository\ngit clone https://github.com/sczhou/CodeFormer\ncd CodeFormer\n\n# create new anaconda env\nconda create -n codeformer python=3.8 -y\nconda activate codeformer\n\n# install python dependencies\npip3 install -r requirements.txt\npython basicsr/setup.py develop\nconda install -c conda-forge dlib (only for face detection or cropping with dlib)\"><pre class=\"notranslate\"><code># git clone this repository\ngit clone https://github.com/sczhou/CodeFormer\ncd CodeFormer\n\n# create new anaconda env\nconda create -n codeformer python=3.8 -y\nconda activate codeformer\n\n# install python dependencies\npip3 install -r requirements.txt\npython basicsr/setup.py develop\nconda install -c conda-forge dlib (only for face detection or cropping with dlib)\n</code></pre></div>\n\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Quick Inference</h3><a id=\"user-content-quick-inference\" class=\"anchor\" aria-label=\"Permalink: Quick Inference\" href=\"#quick-inference\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Download Pre-trained Models:</h4><a id=\"user-content-download-pre-trained-models\" class=\"anchor\" aria-label=\"Permalink: Download Pre-trained Models:\" href=\"#download-pre-trained-models\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Download the facelib and dlib pretrained models from [<a href=\"https://github.com/sczhou/CodeFormer/releases/tag/v0.1.0\">Releases</a> | <a href=\"https://drive.google.com/drive/folders/1b_3qwrzY_kTQh0-SnBoGBgOrJ_PLZSKm?usp=sharing\" rel=\"nofollow\">Google Drive</a> | <a href=\"https://entuedu-my.sharepoint.com/:f:/g/personal/s200094_e_ntu_edu_sg/EvDxR7FcAbZMp_MA9ouq7aQB8XTppMb3-T0uGZ_2anI2mg?e=DXsJFo\" rel=\"nofollow\">OneDrive</a>] to the <code>weights/facelib</code> folder. You can manually download the pretrained models OR download by running the following command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python scripts/download_pretrained_models.py facelib\npython scripts/download_pretrained_models.py dlib (only for dlib face detector)\"><pre class=\"notranslate\"><code>python scripts/download_pretrained_models.py facelib\npython scripts/download_pretrained_models.py dlib (only for dlib face detector)\n</code></pre></div>\n<p dir=\"auto\">Download the CodeFormer pretrained models from [<a href=\"https://github.com/sczhou/CodeFormer/releases/tag/v0.1.0\">Releases</a> | <a href=\"https://drive.google.com/drive/folders/1CNNByjHDFt0b95q54yMVp6Ifo5iuU6QS?usp=sharing\" rel=\"nofollow\">Google Drive</a> | <a href=\"https://entuedu-my.sharepoint.com/:f:/g/personal/s200094_e_ntu_edu_sg/EoKFj4wo8cdIn2-TY2IV6CYBhZ0pIG4kUOeHdPR_A5nlbg?e=AO8UN9\" rel=\"nofollow\">OneDrive</a>] to the <code>weights/CodeFormer</code> folder. You can manually download the pretrained models OR download by running the following command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python scripts/download_pretrained_models.py CodeFormer\"><pre class=\"notranslate\"><code>python scripts/download_pretrained_models.py CodeFormer\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Prepare Testing Data:</h4><a id=\"user-content-prepare-testing-data\" class=\"anchor\" aria-label=\"Permalink: Prepare Testing Data:\" href=\"#prepare-testing-data\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">You can put the testing images in the <code>inputs/TestWhole</code> folder. If you would like to test on cropped and aligned faces, you can put them in the <code>inputs/cropped_faces</code> folder. You can get the cropped and aligned faces by running the following command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"# you may need to install dlib via: conda install -c conda-forge dlib\npython scripts/crop_align_face.py -i [input folder] -o [output folder]\"><pre class=\"notranslate\"><code># you may need to install dlib via: conda install -c conda-forge dlib\npython scripts/crop_align_face.py -i [input folder] -o [output folder]\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Testing:</h4><a id=\"user-content-testing\" class=\"anchor\" aria-label=\"Permalink: Testing:\" href=\"#testing\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">[Note] If you want to compare CodeFormer in your paper, please run the following command indicating <code>--has_aligned</code> (for cropped and aligned face), as the command for the whole image will involve a process of face-background fusion that may damage hair texture on the boundary, which leads to unfair comparison.</p>\n<p dir=\"auto\">Fidelity weight <em>w</em> lays in [0, 1]. Generally, smaller <em>w</em> tends to produce a higher-quality result, while larger <em>w</em> yields a higher-fidelity result. The results will be saved in the <code>results</code> folder.</p>\n<p dir=\"auto\">üßëüèª Face Restoration (cropped and aligned face)</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"# For cropped and aligned faces (512x512)\npython inference_codeformer.py -w 0.5 --has_aligned --input_path [image folder]|[image path]\"><pre class=\"notranslate\"><code># For cropped and aligned faces (512x512)\npython inference_codeformer.py -w 0.5 --has_aligned --input_path [image folder]|[image path]\n</code></pre></div>\n<p dir=\"auto\">üñºÔ∏è Whole Image Enhancement</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"# For whole image\n# Add '--bg_upsampler realesrgan' to enhance the background regions with Real-ESRGAN\n# Add '--face_upsample' to further upsample restorated face with Real-ESRGAN\npython inference_codeformer.py -w 0.7 --input_path [image folder]|[image path]\"><pre class=\"notranslate\"><code># For whole image\n# Add '--bg_upsampler realesrgan' to enhance the background regions with Real-ESRGAN\n# Add '--face_upsample' to further upsample restorated face with Real-ESRGAN\npython inference_codeformer.py -w 0.7 --input_path [image folder]|[image path]\n</code></pre></div>\n<p dir=\"auto\">üé¨ Video Enhancement</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"# For Windows/Mac users, please install ffmpeg first\nconda install -c conda-forge ffmpeg\"><pre class=\"notranslate\"><code># For Windows/Mac users, please install ffmpeg first\nconda install -c conda-forge ffmpeg\n</code></pre></div>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"# For video clips\n# Video path should end with '.mp4'|'.mov'|'.avi'\npython inference_codeformer.py --bg_upsampler realesrgan --face_upsample -w 1.0 --input_path [video path]\"><pre class=\"notranslate\"><code># For video clips\n# Video path should end with '.mp4'|'.mov'|'.avi'\npython inference_codeformer.py --bg_upsampler realesrgan --face_upsample -w 1.0 --input_path [video path]\n</code></pre></div>\n<p dir=\"auto\">üåà Face Colorization (cropped and aligned face)</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"# For cropped and aligned faces (512x512)\n# Colorize black and white or faded photo\npython inference_colorization.py --input_path [image folder]|[image path]\"><pre class=\"notranslate\"><code># For cropped and aligned faces (512x512)\n# Colorize black and white or faded photo\npython inference_colorization.py --input_path [image folder]|[image path]\n</code></pre></div>\n<p dir=\"auto\">üé® Face Inpainting (cropped and aligned face)</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"# For cropped and aligned faces (512x512)\n# Inputs could be masked by white brush using an image editing app (e.g., Photoshop) \n# (check out the examples in inputs/masked_faces)\npython inference_inpainting.py --input_path [image folder]|[image path]\"><pre class=\"notranslate\"><code># For cropped and aligned faces (512x512)\n# Inputs could be masked by white brush using an image editing app (e.g., Photoshop) \n# (check out the examples in inputs/masked_faces)\npython inference_inpainting.py --input_path [image folder]|[image path]\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Training:</h3><a id=\"user-content-training\" class=\"anchor\" aria-label=\"Permalink: Training:\" href=\"#training\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">The training commands can be found in the documents: <a href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/docs/train.md\">English</a> <strong>|</strong> <a href=\"https://github.com/sczhou/CodeFormer/blob/HEAD/docs/train_CN.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a>.</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">License</h3><a id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">This project is licensed under <a href=\"https://github.com/sczhou/CodeFormer/blob/master/LICENSE\">NTU S-Lab License 1.0</a>. Redistribution and use should follow this license.</p>\n<hr>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">üêº Ecosystem Applications &amp; Deployments</h3><a id=\"user-content--ecosystem-applications--deployments\" class=\"anchor\" aria-label=\"Permalink: üêº Ecosystem Applications &amp; Deployments\" href=\"#-ecosystem-applications--deployments\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">CodeFormer has been widely adopted and deployed across a broad range (&gt;20) of online applications, platforms, API services, and independent websites, and has also been integrated into many open-source projects and toolkits.</p>\n<blockquote>\n<p dir=\"auto\">Only demos on <strong>Hugging Face Space</strong>, <strong>Replicate</strong>, and <strong>OpenXLab</strong> are official deployments <strong>maintained by the authors</strong>. All other demos, APIs, apps, websites, and integrations listed below are <strong>third-party (non-official)</strong> and are not affiliated with the CodeFormer authors. Please verify their legitimacy to avoid potential financial loss.</p>\n</blockquote>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Websites (Non-official)</h4><a id=\"user-content-websites-non-official\" class=\"anchor\" aria-label=\"Permalink: Websites (Non-official)\" href=\"#websites-non-official\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\"><g-emoji class=\"g-emoji\" alias=\"warning\">‚ö†Ô∏è</g-emoji><g-emoji class=\"g-emoji\" alias=\"warning\">‚ö†Ô∏è</g-emoji><g-emoji class=\"g-emoji\" alias=\"warning\">‚ö†Ô∏è</g-emoji> The following websites are <strong>not official and are not operated by us</strong>. They use our models without any license or authorization. Please verify their legitimacy to avoid potential financial loss.</p>\n<markdown-accessiblity-table><table>\n<thead>\n<tr>\n<th>Website</th>\n<th>Link</th>\n<th>Notes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CodeFormer.net</td>\n<td><a href=\"https://codeformer.net/\" rel=\"nofollow\">https://codeformer.net/</a></td>\n<td>Non-official website</td>\n</tr>\n<tr>\n<td>CodeFormer.cn</td>\n<td><a href=\"https://www.codeformer.cn/\" rel=\"nofollow\">https://www.codeformer.cn/</a></td>\n<td>Non-official website</td>\n</tr>\n<tr>\n<td>CodeFormerAI.com</td>\n<td><a href=\"https://codeformerai.com/\" rel=\"nofollow\">https://codeformerai.com/</a></td>\n<td>Non-official website</td>\n</tr>\n</tbody>\n</table></markdown-accessiblity-table>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Online Demos / API Platforms</h4><a id=\"user-content-online-demos--api-platforms\" class=\"anchor\" aria-label=\"Permalink: Online Demos / API Platforms\" href=\"#online-demos--api-platforms\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<markdown-accessiblity-table><table>\n<thead>\n<tr>\n<th>Platform</th>\n<th>Link</th>\n<th>Notes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Hugging Face</td>\n<td><a href=\"https://huggingface.co/spaces/sczhou/CodeFormer\" rel=\"nofollow\">https://huggingface.co/spaces/sczhou/CodeFormer</a></td>\n<td>Maintained by Authors</td>\n</tr>\n<tr>\n<td>Replicate</td>\n<td><a href=\"https://replicate.com/sczhou/codeformer\" rel=\"nofollow\">https://replicate.com/sczhou/codeformer</a></td>\n<td>Maintained by Authors</td>\n</tr>\n<tr>\n<td>OpenXLab</td>\n<td><a href=\"https://openxlab.org.cn/apps/detail/ShangchenZhou/CodeFormer\" rel=\"nofollow\">https://openxlab.org.cn/apps/detail/ShangchenZhou/CodeFormer</a></td>\n<td>Maintained by Authors</td>\n</tr>\n<tr>\n<td>Segmind</td>\n<td><a href=\"https://www.segmind.com/models/codeformer\" rel=\"nofollow\">https://www.segmind.com/models/codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>Sieve</td>\n<td><a href=\"https://www.sievedata.com/functions/sieve/codeformer\" rel=\"nofollow\">https://www.sievedata.com/functions/sieve/codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>Fal.ai</td>\n<td><a href=\"https://fal.ai/models/fal-ai/codeformer\" rel=\"nofollow\">https://fal.ai/models/fal-ai/codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>VaikerAI</td>\n<td><a href=\"https://vaikerai.com/sczhou/codeformer\" rel=\"nofollow\">https://vaikerai.com/sczhou/codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>Scade.pro</td>\n<td><a href=\"https://www.scade.pro/processors/lucataco-codeformer\" rel=\"nofollow\">https://www.scade.pro/processors/lucataco-codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>Grandline</td>\n<td><a href=\"https://www.grandline.ai/model/codeformer\" rel=\"nofollow\">https://www.grandline.ai/model/codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>AI Demos</td>\n<td><a href=\"https://aidemos.com/tools/codeformer\" rel=\"nofollow\">https://aidemos.com/tools/codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>Synexa</td>\n<td><a href=\"https://synexa.ai/explore/sczhou/codeformer\" rel=\"nofollow\">https://synexa.ai/explore/sczhou/codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>RentPrompts</td>\n<td><a href=\"https://rentprompts.ai/models/Codeformer\" rel=\"nofollow\">https://rentprompts.ai/models/Codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>ElevaticsAI</td>\n<td><a href=\"https://elevatics.ai/models/super-resolution/codeformer\" rel=\"nofollow\">https://elevatics.ai/models/super-resolution/codeformer</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>Anakin.ai</td>\n<td><a href=\"https://anakin.ai/apps/codeformer-online-face-restoration-by-codeformer-19343\" rel=\"nofollow\">https://anakin.ai/apps/codeformer-online-face-restoration-by-codeformer-19343</a></td>\n<td>Non-official</td>\n</tr>\n<tr>\n<td>Relayto</td>\n<td><a href=\"https://relayto.com/explore/codeformer-yf9rj8kwc7zsr\" rel=\"nofollow\">https://relayto.com/explore/codeformer-yf9rj8kwc7zsr</a></td>\n<td>Non-official</td>\n</tr>\n</tbody>\n</table></markdown-accessiblity-table>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Open-Source Projects &amp; Toolkits</h4><a id=\"user-content-open-source-projects--toolkits\" class=\"anchor\" aria-label=\"Permalink: Open-Source Projects &amp; Toolkits\" href=\"#open-source-projects--toolkits\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<markdown-accessiblity-table><table>\n<thead>\n<tr>\n<th>Project / Toolkit</th>\n<th>Link</th>\n<th>Notes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Stable Diffusion GUI</td>\n<td><a href=\"https://nmkd.itch.io/t2i-gui\" rel=\"nofollow\">https://nmkd.itch.io/t2i-gui</a></td>\n<td>Integration</td>\n</tr>\n<tr>\n<td>Stable Diffusion WebUI</td>\n<td><a href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui\">https://github.com/AUTOMATIC1111/stable-diffusion-webui</a></td>\n<td>Integration</td>\n</tr>\n<tr>\n<td>ChaiNNer</td>\n<td><a href=\"https://github.com/chaiNNer-org/chaiNNer\">https://github.com/chaiNNer-org/chaiNNer</a></td>\n<td>Integration</td>\n</tr>\n<tr>\n<td>PyPI</td>\n<td><a href=\"https://pypi.org/project/codeformer/\" rel=\"nofollow\">https://pypi.org/project/codeformer/</a> ; <a href=\"https://pypi.org/project/codeformer-pip/\" rel=\"nofollow\">https://pypi.org/project/codeformer-pip/</a></td>\n<td>Python packages</td>\n</tr>\n<tr>\n<td>ComfyUI</td>\n<td><a href=\"https://stable-diffusion-art.com/codeformer/\" rel=\"nofollow\">https://stable-diffusion-art.com/codeformer/</a></td>\n<td>Integration</td>\n</tr>\n</tbody>\n</table></markdown-accessiblity-table>\n<hr>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Acknowledgement</h3><a id=\"user-content-acknowledgement\" class=\"anchor\" aria-label=\"Permalink: Acknowledgement\" href=\"#acknowledgement\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">This project is based on <a href=\"https://github.com/XPixelGroup/BasicSR\">BasicSR</a>. Some codes are brought from <a href=\"https://github.com/samb-t/unleashing-transformers\">Unleashing Transformers</a>, <a href=\"https://github.com/deepcam-cn/yolov5-face\">YOLOv5-face</a>, and <a href=\"https://github.com/xinntao/facexlib\">FaceXLib</a>. We also adopt <a href=\"https://github.com/xinntao/Real-ESRGAN\">Real-ESRGAN</a> to support background image enhancement. Thanks for their awesome works.</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Citation</h3><a id=\"user-content-citation\" class=\"anchor\" aria-label=\"Permalink: Citation\" href=\"#citation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">If our work is useful for your research, please consider citing:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"@inproceedings{zhou2022codeformer,\n    author = {Zhou, Shangchen and Chan, Kelvin C.K. and Li, Chongyi and Loy, Chen Change},\n    title = {Towards Robust Blind Face Restoration with Codebook Lookup TransFormer},\n    booktitle = {NeurIPS},\n    year = {2022}\n}\"><pre class=\"notranslate\"><code>@inproceedings{zhou2022codeformer,\n    author = {Zhou, Shangchen and Chan, Kelvin C.K. and Li, Chongyi and Loy, Chen Change},\n    title = {Towards Robust Blind Face Restoration with Codebook Lookup TransFormer},\n    booktitle = {NeurIPS},\n    year = {2022}\n}\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Contact</h3><a id=\"user-content-contact\" class=\"anchor\" aria-label=\"Permalink: Contact\" href=\"#contact\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">If you have any questions, please feel free to reach me out at <code>shangchenzhou@gmail.com</code>.</p>\n</article></div>"
}