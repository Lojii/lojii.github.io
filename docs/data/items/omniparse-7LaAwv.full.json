{
  "id": "omniparse-7LaAwv",
  "type": "repo",
  "name": "omniparse",
  "nameEn": "omniparse",
  "url": "https://github.com/adithya-s-k/omniparse",
  "homepage": "https://omniparse.cognitivelab.in/",
  "summary": "ä¸€ä¸ªæ•°æ®æ‘„å–/è§£æå¹³å°ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤æ‘„å–å„ç±»æ•°æ®ï¼Œå¦‚æ–‡æ¡£ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘å’Œç½‘ç»œå†…å®¹ï¼Œå¹¶è·å¾—æœ€é€‚åˆç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰ä½¿ç”¨çš„ç»“æ„åŒ–ã€å¯æ“ä½œè¾“å‡ºã€‚",
  "description": "",
  "notes": "",
  "images": [
    "/assets/images/omniparse-7LaAwv/1.jpg"
  ],
  "thumbnail": "/assets/images/omniparse-7LaAwv/thumb.jpg",
  "category": "ai",
  "tags": [
    "æ ¼å¼è½¬æ¢",
    "è‡ªåŠ¨åŒ–"
  ],
  "github": {
    "stars": 6781,
    "forks": 538,
    "language": "Python",
    "license": "GPL-3.0",
    "lastUpdate": "2026-01-20",
    "topics": [
      "ingestion-api",
      "ocr",
      "omniparser",
      "parse-server",
      "parser-library",
      "vision-transformer",
      "web-crawler",
      "whisper-api"
    ],
    "createdAt": "2024-06-04"
  },
  "archived": false,
  "createdAt": "2026-01-23",
  "updatedAt": "2026-01-23",
  "originalContent": "<div id=\"readme\" class=\"md\" data-path=\"README.md\"><article class=\"markdown-body entry-content container-lg\" itemprop=\"text\"><div class=\"markdown-heading\" dir=\"auto\"><h1 class=\"heading-element\" dir=\"auto\">OmniParse</h1><a id=\"user-content-omniparse\" class=\"anchor\" aria-label=\"Permalink: OmniParse\" href=\"#omniparse\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/adithya-s-k/omniparse/main/docs/assets/hero_image_2.png\"><img src=\"https://raw.githubusercontent.com/adithya-s-k/omniparse/main/docs/assets/hero_image_2.png\" alt=\"OmniParse\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/adithya-s-k/omniparse/stargazers\"><img src=\"https://camo.githubusercontent.com/b3aec734b21376d48fb1a4bd0a1891a7c267ae3488d881434d53afd5687a4607/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616469746879612d732d6b2f6f6d6e6970617273653f7374796c653d736f6369616c\" alt=\"GitHub Stars\" data-canonical-src=\"https://img.shields.io/github/stars/adithya-s-k/omniparse?style=social\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/adithya-s-k/omniparse/network/members\"><img src=\"https://camo.githubusercontent.com/b24aa3ab0577323fafc11dd3e702950405259f594d2de16ef2562f68d7d07a9a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f616469746879612d732d6b2f6f6d6e6970617273653f7374796c653d736f6369616c\" alt=\"GitHub Forks\" data-canonical-src=\"https://img.shields.io/github/forks/adithya-s-k/omniparse?style=social\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/adithya-s-k/omniparse/issues\"><img src=\"https://camo.githubusercontent.com/b9c4dd0a2ee72ac3cfa2180b0eaa40a4fa688e12b7c2e9501c9c2c5a074c6892/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f616469746879612d732d6b2f6f6d6e697061727365\" alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/adithya-s-k/omniparse\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/adithya-s-k/omniparse/pulls\"><img src=\"https://camo.githubusercontent.com/e4d0aa052e6c8460b305b22a27f04871921319ef1136fdc602b11d6dd9cac270/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f616469746879612d732d6b2f6f6d6e697061727365\" alt=\"GitHub Pull Requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/adithya-s-k/omniparse\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/adithya-s-k/omniparse/blob/main/LICENSE\"><img src=\"https://camo.githubusercontent.com/db53818c1dcec67b70db3f2a594e562deb688c11e10c235ddb0de91027b726e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f616469746879612d732d6b2f6f6d6e697061727365\" alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/adithya-s-k/omniparse\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-alert markdown-alert-important\" dir=\"auto\"><p class=\"markdown-alert-title\" dir=\"auto\"><svg class=\"octicon octicon-report mr-2\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0 1 14.25 13H8.06l-2.573 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25Zm7 2.25v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 9a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>Important</p>\n<p dir=\"auto\">OmniParse is a platform that ingests and parses any unstructured data into structured, actionable data optimized for GenAI (LLM) applications. Whether you are working with documents, tables, images, videos, audio files, or web pages, OmniParse prepares your data to be clean, structured, and ready for AI applications such as RAG, fine-tuning, and more</p>\n</div>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Try it out</h2><a id=\"user-content-try-it-out\" class=\"anchor\" aria-label=\"Permalink: Try it out\" href=\"#try-it-out\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\"><a href=\"https://colab.research.google.com/github/adithya-s-k/omniparse/blob/main/examples/OmniParse_GoogleColab.ipynb\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/eff96fda6b2e0fff8cdf2978f89d61aa434bb98c00453ae23dd0aab8d1451633/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667\" alt=\"Open In Colab\" data-canonical-src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Intro</h2><a id=\"user-content-intro\" class=\"anchor\" aria-label=\"Permalink: Intro\" href=\"#intro\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<details open=\"\" class=\"details-reset border rounded-2\">\n  <summary class=\"px-3 py-2\">\n    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-device-camera-video\">\n    <path d=\"M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z\"></path>\n</svg>\n    <span class=\"m-1\">OmniParse.1.mp4</span>\n    <span class=\"dropdown-caret\"></span>\n  </summary>\n\n  <video src=\"https://private-user-images.githubusercontent.com/27956426/345913951-457d8b5b-9573-44da-8bcf-616000651a13.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjkxMzAyNjUsIm5iZiI6MTc2OTEyOTk2NSwicGF0aCI6Ii8yNzk1NjQyNi8zNDU5MTM5NTEtNDU3ZDhiNWItOTU3My00NGRhLThiY2YtNjE2MDAwNjUxYTEzLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMjMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTIzVDAwNTkyNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTAwYmRkNTZkMmY4MjYyNTA3OTExYjNiNDA2OGZkZGZjZGM3ZjgzYTY3YWJlY2VlMzYwOTIxNzE1MjkyYWEzMGYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.wHYY2KUsJQGTCu-p0jhyhgjhDn3ATW6I2yOg3lX-jg0\" data-canonical-src=\"https://private-user-images.githubusercontent.com/27956426/345913951-457d8b5b-9573-44da-8bcf-616000651a13.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjkxMzAyNjUsIm5iZiI6MTc2OTEyOTk2NSwicGF0aCI6Ii8yNzk1NjQyNi8zNDU5MTM5NTEtNDU3ZDhiNWItOTU3My00NGRhLThiY2YtNjE2MDAwNjUxYTEzLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMjMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTIzVDAwNTkyNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTAwYmRkNTZkMmY4MjYyNTA3OTExYjNiNDA2OGZkZGZjZGM3ZjgzYTY3YWJlY2VlMzYwOTIxNzE1MjkyYWEzMGYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.wHYY2KUsJQGTCu-p0jhyhgjhDn3ATW6I2yOg3lX-jg0\" controls=\"controls\" muted=\"muted\" class=\"d-block rounded-bottom-2 border-top width-fit\" style=\"max-height:640px; min-height: 200px\">\n\n  </video>\n</details>\n\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Features</h2><a id=\"user-content-features\" class=\"anchor\" aria-label=\"Permalink: Features\" href=\"#features\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">âœ… Completely local, no external APIs  <br>\nâœ… Fits in a T4 GPU <br>\nâœ… Supports ~20 file types  <br>\nâœ… Convert documents, multimedia, and web pages to high-quality structured markdown  <br>\nâœ… Table extraction, image extraction/captioning, audio/video transcription, web page crawling  <br>\nâœ… Easily deployable using Docker and Skypilot  <br>\nâœ… Colab friendly  <br>\nâœ… Interative UI powered by Gradio</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Why OmniParse ?</h3><a id=\"user-content-why-omniparse-\" class=\"anchor\" aria-label=\"Permalink: Why OmniParse ?\" href=\"#why-omniparse-\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">It's challenging to process data as it comes in different shapes and sizes. OmniParse aims to be an ingestion/parsing platform where you can ingest any type of data, such as documents, images, audio, video, and web content, and get the most structured and actionable output that is GenAI (LLM) friendly.</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Installation</h2><a id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<div class=\"markdown-alert markdown-alert-important\" dir=\"auto\"><p class=\"markdown-alert-title\" dir=\"auto\"><svg class=\"octicon octicon-report mr-2\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0 1 14.25 13H8.06l-2.573 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25Zm7 2.25v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 9a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path></svg>Important</p><p dir=\"auto\">The server only works on Linux-based systems. This is due to certain dependencies and system-specific configurations that are not compatible with Windows or macOS.</p>\n</div>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"git clone https://github.com/adithya-s-k/omniparse\ncd omniparse\"><pre>git clone https://github.com/adithya-s-k/omniparse\n<span class=\"pl-c1\">cd</span> omniparse</pre></div>\n<p dir=\"auto\">Create a Virtual Environment:</p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"conda create -n omniparse-venv python=3.10\nconda activate omniparse-venv\"><pre>conda create -n omniparse-venv python=3.10\nconda activate omniparse-venv</pre></div>\n<p dir=\"auto\">Install Dependencies:</p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"poetry install\n# or\npip install -e .\n# or\npip install -r pyproject.toml\"><pre>poetry install\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> or</span>\npip install -e <span class=\"pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> or</span>\npip install -r pyproject.toml</pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">ğŸ›³ï¸ Docker</h3><a id=\"user-content-ï¸-docker\" class=\"anchor\" aria-label=\"Permalink: ğŸ›³ï¸ Docker\" href=\"#ï¸-docker\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">To use OmniParse with Docker, execute the following commands:</p>\n<ol dir=\"auto\">\n<li>Pull the OmniParse API Docker image from Docker Hub:</li>\n<li>Run the Docker container, exposing port 8000:\nğŸ‘‰ğŸ¼<a href=\"https://hub.docker.com/r/savatar101/omniparse\" rel=\"nofollow\">Docker Image</a></li>\n</ol>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"docker pull savatar101/omniparse:0.1\n# if you are running on a gpu \ndocker run --gpus all -p 8000:8000 savatar101/omniparse:0.1\n# else\ndocker run -p 8000:8000 savatar101/omniparse:0.1\"><pre>docker pull savatar101/omniparse:0.1\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> if you are running on a gpu </span>\ndocker run --gpus all -p 8000:8000 savatar101/omniparse:0.1\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> else</span>\ndocker run -p 8000:8000 savatar101/omniparse:0.1</pre></div>\n<p dir=\"auto\">Alternatively, if you prefer to build the Docker image locally:\nThen, run the Docker container as follows:</p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"docker build -t omniparse .\n# if you are running on a gpu\ndocker run --gpus all -p 8000:8000 omniparse\n# else\ndocker run -p 8000:8000 omniparse\n\"><pre>docker build -t omniparse <span class=\"pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> if you are running on a gpu</span>\ndocker run --gpus all -p 8000:8000 omniparse\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> else</span>\ndocker run -p 8000:8000 omniparse\n</pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Usage</h2><a id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Run the Server:</p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"python server.py --host 0.0.0.0 --port 8000 --documents --media --web\"><pre>python server.py --host 0.0.0.0 --port 8000 --documents --media --web</pre></div>\n<ul dir=\"auto\">\n<li><code>--documents</code>: Load in all the models that help you parse and ingest documents (Surya OCR series of models and Florence-2).</li>\n<li><code>--media</code>: Load in Whisper model to transcribe audio and video files.</li>\n<li><code>--web</code>: Set up selenium crawler.</li>\n</ul>\n<p dir=\"auto\">Download Models:\nIf you want to download the models before starting the server</p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"python download.py --documents --media --web\"><pre>python download.py --documents --media --web</pre></div>\n<ul dir=\"auto\">\n<li><code>--documents</code>: Load in all the models that help you parse and ingest documents (Surya OCR series of models and Florence-2).</li>\n<li><code>--media</code>: Load in Whisper model to transcribe audio and video files.</li>\n<li><code>--web</code>: Set up selenium crawler.</li>\n</ul>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Supported Data Types</h2><a id=\"user-content-supported-data-types\" class=\"anchor\" aria-label=\"Permalink: Supported Data Types\" href=\"#supported-data-types\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<markdown-accessiblity-table><table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Supported Extensions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Documents</td>\n<td>.doc, .docx, .pdf, .ppt, .pptx</td>\n</tr>\n<tr>\n<td>Images</td>\n<td>.png, .jpg, .jpeg, .tiff, .bmp, .heic</td>\n</tr>\n<tr>\n<td>Video</td>\n<td>.mp4, .mkv, .avi, .mov</td>\n</tr>\n<tr>\n<td>Audio</td>\n<td>.mp3, .wav, .aac</td>\n</tr>\n<tr>\n<td>Web</td>\n<td>dynamic webpages, http://.com</td>\n</tr>\n</tbody>\n</table></markdown-accessiblity-table>\n<details>\n<summary><div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">API Endpoints</h2><a id=\"user-content-api-endpoints\" class=\"anchor\" aria-label=\"Permalink: API Endpoints\" href=\"#api-endpoints\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div></summary>\n<blockquote>\n<p dir=\"auto\">Client library compatible with Langchain, llamaindex, and haystack integrations coming soon.</p>\n</blockquote>\n<ul dir=\"auto\">\n<li><a href=\"#api-endpoints\">API Endpoints</a>\n<ul dir=\"auto\">\n<li><a href=\"#document-parsing\">Document Parsing</a>\n<ul dir=\"auto\">\n<li><a href=\"#parse-any-document\">Parse Any Document</a></li>\n<li><a href=\"#parse-pdf\">Parse PDF</a></li>\n<li><a href=\"#parse-powerpoint\">Parse PowerPoint</a></li>\n<li><a href=\"#parse-word-document\">Parse Word Document</a></li>\n</ul>\n</li>\n<li><a href=\"#media-parsing\">Media Parsing</a>\n<ul dir=\"auto\">\n<li><a href=\"#parse-any-media\">Parse Any Media</a></li>\n<li><a href=\"#parse-image\">Parse Image</a></li>\n<li><a href=\"#process-image\">Process Image</a></li>\n<li><a href=\"#parse-video\">Parse Video</a></li>\n<li><a href=\"#parse-audio\">Parse Audio</a></li>\n</ul>\n</li>\n<li><a href=\"#website-parsing\">Website Parsing</a>\n<ul dir=\"auto\">\n<li><a href=\"#parse-website\">Parse Website</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Document Parsing</h3><a id=\"user-content-document-parsing\" class=\"anchor\" aria-label=\"Permalink: Document Parsing\" href=\"#document-parsing\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Parse Any Document</h4><a id=\"user-content-parse-any-document\" class=\"anchor\" aria-label=\"Permalink: Parse Any Document\" href=\"#parse-any-document\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Endpoint: <code>/parse_document</code>\nMethod: POST</p>\n<p dir=\"auto\">Parses PDF, PowerPoint, or Word documents.</p>\n<p dir=\"auto\">Curl command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"curl -X POST -F &quot;file=@/path/to/document&quot; http://localhost:8000/parse_document\"><pre class=\"notranslate\"><code>curl -X POST -F \"file=@/path/to/document\" http://localhost:8000/parse_document\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Parse PDF</h4><a id=\"user-content-parse-pdf\" class=\"anchor\" aria-label=\"Permalink: Parse PDF\" href=\"#parse-pdf\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Endpoint: <code>/parse_document/pdf</code>\nMethod: POST</p>\n<p dir=\"auto\">Parses PDF documents.</p>\n<p dir=\"auto\">Curl command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"curl -X POST -F &quot;file=@/path/to/document.pdf&quot; http://localhost:8000/parse_document/pdf\"><pre class=\"notranslate\"><code>curl -X POST -F \"file=@/path/to/document.pdf\" http://localhost:8000/parse_document/pdf\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Parse PowerPoint</h4><a id=\"user-content-parse-powerpoint\" class=\"anchor\" aria-label=\"Permalink: Parse PowerPoint\" href=\"#parse-powerpoint\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Endpoint: <code>/parse_document/ppt</code>\nMethod: POST</p>\n<p dir=\"auto\">Parses PowerPoint presentations.</p>\n<p dir=\"auto\">Curl command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"curl -X POST -F &quot;file=@/path/to/presentation.ppt&quot; http://localhost:8000/parse_document/ppt\"><pre class=\"notranslate\"><code>curl -X POST -F \"file=@/path/to/presentation.ppt\" http://localhost:8000/parse_document/ppt\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Parse Word Document</h4><a id=\"user-content-parse-word-document\" class=\"anchor\" aria-label=\"Permalink: Parse Word Document\" href=\"#parse-word-document\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Endpoint: <code>/parse_document/docs</code>\nMethod: POST</p>\n<p dir=\"auto\">Parses Word documents.</p>\n<p dir=\"auto\">Curl command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"curl -X POST -F &quot;file=@/path/to/document.docx&quot; http://localhost:8000/parse_document/docs\"><pre class=\"notranslate\"><code>curl -X POST -F \"file=@/path/to/document.docx\" http://localhost:8000/parse_document/docs\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Media Parsing</h3><a id=\"user-content-media-parsing\" class=\"anchor\" aria-label=\"Permalink: Media Parsing\" href=\"#media-parsing\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Parse Image</h4><a id=\"user-content-parse-image\" class=\"anchor\" aria-label=\"Permalink: Parse Image\" href=\"#parse-image\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Endpoint: <code>/parse_image/image</code>\nMethod: POST</p>\n<p dir=\"auto\">Parses image files (PNG, JPEG, JPG, TIFF, WEBP).</p>\n<p dir=\"auto\">Curl command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"curl -X POST -F &quot;file=@/path/to/image.jpg&quot; http://localhost:8000/parse_media/image\"><pre class=\"notranslate\"><code>curl -X POST -F \"file=@/path/to/image.jpg\" http://localhost:8000/parse_media/image\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Process Image</h4><a id=\"user-content-process-image\" class=\"anchor\" aria-label=\"Permalink: Process Image\" href=\"#process-image\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Endpoint: <code>/parse_image/process_image</code>\nMethod: POST</p>\n<p dir=\"auto\">Processes an image with a specific task.</p>\n<p dir=\"auto\">Possible task inputs:\n<code>OCR | OCR with Region | Caption | Detailed Caption | More Detailed Caption | Object Detection | Dense Region Caption | Region Proposal</code></p>\n<p dir=\"auto\">Curl command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"curl -X POST -F &quot;image=@/path/to/image.jpg&quot; -F &quot;task=Caption&quot; -F &quot;prompt=Optional prompt&quot; http://localhost:8000/parse_media/process_image\"><pre class=\"notranslate\"><code>curl -X POST -F \"image=@/path/to/image.jpg\" -F \"task=Caption\" -F \"prompt=Optional prompt\" http://localhost:8000/parse_media/process_image\n</code></pre></div>\n<p dir=\"auto\">Arguments:</p>\n<ul dir=\"auto\">\n<li><code>image</code>: The image file</li>\n<li><code>task</code>: The processing task (e.g., Caption, Object Detection)</li>\n<li><code>prompt</code>: Optional prompt for certain tasks</li>\n</ul>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Parse Video</h4><a id=\"user-content-parse-video\" class=\"anchor\" aria-label=\"Permalink: Parse Video\" href=\"#parse-video\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Endpoint: <code>/parse_media/video</code>\nMethod: POST</p>\n<p dir=\"auto\">Parses video files (MP4, AVI, MOV, MKV).</p>\n<p dir=\"auto\">Curl command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"curl -X POST -F &quot;file=@/path/to/video.mp4&quot; http://localhost:8000/parse_media/video\"><pre class=\"notranslate\"><code>curl -X POST -F \"file=@/path/to/video.mp4\" http://localhost:8000/parse_media/video\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Parse Audio</h4><a id=\"user-content-parse-audio\" class=\"anchor\" aria-label=\"Permalink: Parse Audio\" href=\"#parse-audio\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Endpoint: <code>/parse_media/audio</code>\nMethod: POST</p>\n<p dir=\"auto\">Parses audio files (MP3, WAV, FLAC).</p>\n<p dir=\"auto\">Curl command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"curl -X POST -F &quot;file=@/path/to/audio.mp3&quot; http://localhost:8000/parse_media/audio\"><pre class=\"notranslate\"><code>curl -X POST -F \"file=@/path/to/audio.mp3\" http://localhost:8000/parse_media/audio\n</code></pre></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Website Parsing</h3><a id=\"user-content-website-parsing\" class=\"anchor\" aria-label=\"Permalink: Website Parsing\" href=\"#website-parsing\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h4 class=\"heading-element\" dir=\"auto\">Parse Website</h4><a id=\"user-content-parse-website\" class=\"anchor\" aria-label=\"Permalink: Parse Website\" href=\"#parse-website\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Endpoint: <code>/parse_website/parse</code>\nMethod: POST</p>\n<p dir=\"auto\">Parses a website given its URL.</p>\n<p dir=\"auto\">Curl command:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"curl -X POST -H &quot;Content-Type: application/json&quot; -d '{&quot;url&quot;: &quot;https://example.com&quot;}' http://localhost:8000/parse_website\"><pre class=\"notranslate\"><code>curl -X POST -H \"Content-Type: application/json\" -d '{\"url\": \"https://example.com\"}' http://localhost:8000/parse_website\n</code></pre></div>\n<p dir=\"auto\">Arguments:</p>\n<ul dir=\"auto\">\n<li><code>url</code>: The URL of the website to parse</li>\n</ul>\n</details>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Coming Soon/ RoadMap</h2><a id=\"user-content-coming-soon-roadmap\" class=\"anchor\" aria-label=\"Permalink: Coming Soon/ RoadMap\" href=\"#coming-soon-roadmap\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">ğŸ¦™ LlamaIndex | Langchain | Haystack integrations coming soon\nğŸ“š Batch processing data\nâ­ Dynamic chunking and structured data extraction based on specified Schema<br>\nğŸ› ï¸ One magic API: just feed in your file prompt what you want, and we will take care of the rest<br>\nğŸ”§ Dynamic model selection and support for external APIs<br>\nğŸ“„ Batch processing for handling multiple files at once<br>\nğŸ“¦ New open-source model to replace Surya OCR and Marker</p>\n<p dir=\"auto\"><strong>Final goal</strong>: replace all the different models currently being used with a single MultiModel Model to parse any type of data and get the data you need.</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Limitations</h2><a id=\"user-content-limitations\" class=\"anchor\" aria-label=\"Permalink: Limitations\" href=\"#limitations\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">There is a need for a GPU with 8~10 GB minimum VRAM as we are using deep learning models.\n\\</p>\n<p dir=\"auto\">Document Parsing Limitations\n\\</p>\n<ul dir=\"auto\">\n<li><a href=\"https://github.com/VikParuchuri/marker\">Marker</a> which is the underlying PDF parser will not convert 100% of equations to LaTeX because it has to detect and then convert them.</li>\n<li>It is good at parsing english but might struggle for languages such as Chinese</li>\n<li>Tables are not always formatted 100% correctly; text can be in the wrong column.</li>\n<li>Whitespace and indentations are not always respected.</li>\n<li>Not all lines/spans will be joined properly.</li>\n<li>This works best on digital PDFs that won't require a lot of OCR. It's optimized for speed, and limited OCR is used to fix errors.</li>\n<li>To fit all the models in the GPU, we are using the smallest variants, which might not offer the best-in-class performance.</li>\n</ul>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">License</h2><a id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">OmniParse is licensed under the GPL-3.0 license. See <code>LICENSE</code> for more information.\nThe project uses Marker under the hood, which has a commercial license that needs to be followed. Here are the details:</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Commercial Usage</h3><a id=\"user-content-commercial-usage\" class=\"anchor\" aria-label=\"Permalink: Commercial Usage\" href=\"#commercial-usage\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Marker and Surya OCR Models are designed to be as widely accessible as possible while still funding development and training costs. Research and personal usage are always allowed, but there are some restrictions on commercial usage.\nThe weights for the models are licensed under cc-by-nc-sa-4.0. However, this restriction is waived for any organization with less than $5M USD in gross revenue in the most recent 12-month period AND less than $5M in lifetime VC/angel funding raised. To remove the GPL license requirements (dual-license) and/or use the weights commercially over the revenue limit, check out the options provided.\nPlease refer to <a href=\"https://github.com/VikParuchuri/marker\">Marker</a> for more Information about the License of the Model weights</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Acknowledgements</h2><a id=\"user-content-acknowledgements\" class=\"anchor\" aria-label=\"Permalink: Acknowledgements\" href=\"#acknowledgements\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">This project builds upon the remarkable <a href=\"https://github.com/VikParuchuri/marker\">Marker</a> project created by <a href=\"https://twitter.com/VikParuchuri\" rel=\"nofollow\">Vik Paruchuri</a>. We express our gratitude for the inspiration and foundation provided by this project. Special thanks to <a href=\"https://github.com/VikParuchuri/surya\">Surya-OCR</a> and <a href=\"https://github.com/VikParuchuri/texify\">Texify</a> for the OCR models extensively used in this project, and to <a href=\"https://github.com/unclecode/crawl4ai\">Crawl4AI</a> for their contributions.</p>\n<p dir=\"auto\">Models being used:</p>\n<ul dir=\"auto\">\n<li>Surya OCR, Detect, Layout, Order, and Texify</li>\n<li>Florence-2 base</li>\n<li>Whisper Small</li>\n</ul>\n<p dir=\"auto\">Thank you to the authors for their contributions to these models.</p>\n<hr>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Contact</h2><a id=\"user-content-contact\" class=\"anchor\" aria-label=\"Permalink: Contact\" href=\"#contact\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p align=\"center\" dir=\"auto\">\n  <a href=\"https://adithyask.com\" rel=\"nofollow\">\n    <img src=\"https://camo.githubusercontent.com/04bb69128d4b4e7d33dbd53bf55445568571645e5d1d5b9c0a69ae8e5cbdf9bc/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d616469746879612d732d6b2f6f6d6e69706172736526747970653d44617465\" alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=adithya-s-k/omniparse&amp;type=Date\" style=\"max-width: 100%;\">\n  </a>\n</p>\nFor any inquiries, please contact us at adithyaskolavi@gmail.com\n\n</article></div>"
}